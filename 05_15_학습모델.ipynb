{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMa1EL+l9uFlVFmqvx0HHUL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erika0915/pattern-recognition/blob/main/05_15_%ED%95%99%EC%8A%B5%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "X_train_final = pd.read_csv('/content/drive/MyDrive/패턴인식/X_train_final.csv')\n",
        "y_train_final = pd.read_csv('/content/drive/MyDrive/패턴인식/y_train_final.csv')\n",
        "X_val = pd.read_csv('/content/drive/MyDrive/패턴인식/X_val.csv')\n",
        "y_val = pd.read_csv('/content/drive/MyDrive/패턴인식/y_val.csv')\n",
        "X_test_scaled = pd.read_csv('/content/drive/MyDrive/패턴인식/X_test_scaled.csv')\n",
        "\n",
        "# y를 Series로 변환\n",
        "y_train_final = y_train_final.squeeze()\n",
        "y_val = y_val.squeeze()\n",
        "\n",
        "print(\"데이터 불러오기 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Ay7seq13yT",
        "outputId": "50e8de63-6a1b-46ca-d44d-bacf61dcee30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "데이터 불러오기 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 튜닝 전 모델"
      ],
      "metadata": {
        "id": "5ovgxwCXG4rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. LightGDM\n"
      ],
      "metadata": {
        "id": "PEpmNGbSHFrB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WllQ1cUJvql2",
        "outputId": "0f6d0d3c-0317-4f47-9be3-bc00fb78506d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 8803, number of negative: 8957\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006236 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8344\n",
            "[LightGBM] [Info] Number of data points in the train set: 17760, number of used features: 55\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495664 -> initscore=-0.017343\n",
            "[LightGBM] [Info] Start training from score -0.017343\n",
            "\n",
            " LightGBM 검증 성능\n",
            " Accuracy: 0.6610\n",
            " F1 Score: 0.6577\n",
            " AUC: 0.7238\n",
            " 최종 평균 점수: 0.6808\n",
            "\n",
            " Test 데이터 예측 결과:\n",
            "Class 0 개수: 4881\n",
            "Class 1 개수: 4634\n"
          ]
        }
      ],
      "source": [
        "# LightGBM 모델 생성 및 학습\n",
        "lgbm_model = LGBMClassifier(\n",
        "    random_state=42,\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1\n",
        ")\n",
        "lgbm_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "# 검증 데이터 예측 및 평가\n",
        "y_val_pred_lgbm = lgbm_model.predict(X_val)\n",
        "y_val_proba_lgbm = lgbm_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "val_acc_lgbm = accuracy_score(y_val, y_val_pred_lgbm)\n",
        "val_f1_lgbm = f1_score(y_val, y_val_pred_lgbm)\n",
        "val_auc_lgbm = roc_auc_score(y_val, y_val_proba_lgbm)\n",
        "val_avg_lgbm = (val_acc_lgbm + val_f1_lgbm + val_auc_lgbm) / 3\n",
        "\n",
        "print(\"\\n LightGBM 검증 성능\")\n",
        "print(f\" Accuracy: {val_acc_lgbm:.4f}\")\n",
        "print(f\" F1 Score: {val_f1_lgbm:.4f}\")\n",
        "print(f\" AUC: {val_auc_lgbm:.4f}\")\n",
        "print(f\" 최종 평균 점수: {val_avg_lgbm:.4f}\")\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "test_preds = lgbm_model.predict(X_test_scaled)\n",
        "unique, counts = np.unique(test_preds, return_counts=True)\n",
        "pred_counts = dict(zip(unique, counts))\n",
        "\n",
        "print(\"\\n Test 데이터 예측 결과:\")\n",
        "print(f\"Class 0 개수: {pred_counts.get(0, 0)}\")\n",
        "print(f\"Class 1 개수: {pred_counts.get(1, 0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 랜덤포레스트"
      ],
      "metadata": {
        "id": "kAJBXo6Q1ZcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest 모델 생성 및 학습\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "# 검증 데이터 예측 및 평가\n",
        "y_val_pred_rf = rf_model.predict(X_val)\n",
        "y_val_proba_rf = rf_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "val_acc_rf = accuracy_score(y_val, y_val_pred_rf)\n",
        "val_f1_rf = f1_score(y_val, y_val_pred_rf)\n",
        "val_auc_rf = roc_auc_score(y_val, y_val_proba_rf)\n",
        "val_avg_rf = (val_acc_rf + val_f1_rf + val_auc_rf) / 3\n",
        "\n",
        "print(\"\\n RandomForest 검증 성능\")\n",
        "print(f\" Accuracy: {val_acc_rf:.4f}\")\n",
        "print(f\" F1 Score: {val_f1_rf:.4f}\")\n",
        "print(f\" AUC: {val_auc_rf:.4f}\")\n",
        "print(f\" 최종 평균 점수: {val_avg_rf:.4f}\")\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "test_preds_rf = rf_model.predict(X_test_scaled)\n",
        "unique_rf, counts_rf = np.unique(test_preds_rf, return_counts=True)\n",
        "pred_counts_rf = dict(zip(unique_rf, counts_rf))\n",
        "\n",
        "print(\"\\n Test 데이터 예측 결과:\")\n",
        "print(f\"Class 0 개수: {pred_counts_rf.get(0, 0)}\")\n",
        "print(f\"Class 1 개수: {pred_counts_rf.get(1, 0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uJ09VSI1cCH",
        "outputId": "9b8e251f-22e9-4c9c-9a21-3088a2ad99fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " RandomForest 검증 성능\n",
            " Accuracy: 0.6637\n",
            " F1 Score: 0.6647\n",
            " AUC: 0.7218\n",
            " 최종 평균 점수: 0.6834\n",
            "\n",
            " Test 데이터 예측 결과:\n",
            "Class 0 개수: 4773\n",
            "Class 1 개수: 4742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 튜닝 모델\n",
        "1. LightGBM 튜닝\n",
        "- `n_estimators`, `learning_rate`, `max_depth`, `num_leaves`, `min_child_samples`, `subsample` 6개 하이퍼파라미터를 랜덤하게 조합해서 실험\n",
        "- RandomizedSearchCV를 사용해서 20번(=n_iter=20) 조합 시도함\n",
        "- 3-fold 교차검증으로 각각의 조합 성능 평가 (ROC AUC 기준)\n",
        "- 제일 좋은 조합(best_params_)을 가진 best_lgbm 모델을 얻음.\n",
        "\n",
        "2. RandomForest\n",
        "- 튜닝 없이 기본 모델을 사용함\n",
        "\n",
        "3. 평가\n",
        "</br>\n",
        "각각 best_lgbm, 기본 RandomRorest 모델을 검증 데이터(X_val, y_val)에서 평가\n",
        "Accuracy, F1 score, AUC를 계산하고, 이 세 개를 평균(Avg) 내서 최종 점수를 출력함."
      ],
      "metadata": {
        "id": "5DW1hfJUHH6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# LightGBM 튜닝할 파라미터 범위 정의\n",
        "lgbm_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [5, 7, 9, 12],\n",
        "    'num_leaves': [20, 31, 50],\n",
        "    'min_child_samples': [10, 20, 30],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "}\n",
        "\n",
        "# LightGBM RandomizedSearchCV 설정\n",
        "lgbm_random_search = RandomizedSearchCV(\n",
        "    LGBMClassifier(random_state=42),\n",
        "    param_distributions=lgbm_params,\n",
        "    n_iter=20,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# LightGBM 튜닝 및 최적 모델 저장\n",
        "lgbm_random_search.fit(X_train_final, y_train_final)\n",
        "best_lgbm = lgbm_random_search.best_estimator_\n",
        "print(\"Best Parameters (LightGBM):\", lgbm_random_search.best_params_)\n",
        "\n",
        "# RandomForest 기본 모델 사용\n",
        "best_rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "best_rf.fit(X_train_final, y_train_final)\n",
        "\n",
        "# 최적 모델 평가 함수 정의\n",
        "def evaluate(model, X_val, y_val, model_name=\"Model\"):\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    auc = roc_auc_score(y_val, y_proba)\n",
        "    avg = (acc + f1 + auc) / 3\n",
        "\n",
        "    print(f\"\\n{model_name} 검증 성능\")\n",
        "    print(f\" Accuracy: {acc:.4f}\")\n",
        "    print(f\" F1 Score: {f1:.4f}\")\n",
        "    print(f\" AUC: {auc:.4f}\")\n",
        "    print(f\" 최종 평균 점수: {avg:.4f}\")\n",
        "\n",
        "# LightGBM 평가\n",
        "evaluate(best_lgbm, X_val, y_val, model_name=\"최적 LGBM\")\n",
        "\n",
        "# RandomForest 평가\n",
        "evaluate(best_rf, X_val, y_val, model_name=\"기본 RandomForest\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVzWaOeyBPSn",
        "outputId": "98e7a0cf-8037-4e09-f262-f316bb10b156"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[LightGBM] [Info] Number of positive: 8803, number of negative: 8957\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018779 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 8344\n",
            "[LightGBM] [Info] Number of data points in the train set: 17760, number of used features: 55\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495664 -> initscore=-0.017343\n",
            "[LightGBM] [Info] Start training from score -0.017343\n",
            "Best Parameters (LightGBM): {'subsample': 0.8, 'num_leaves': 20, 'n_estimators': 300, 'min_child_samples': 30, 'max_depth': 7, 'learning_rate': 0.05}\n",
            "\n",
            "최적 LGBM 검증 성능\n",
            " Accuracy: 0.6617\n",
            " F1 Score: 0.6561\n",
            " AUC: 0.7240\n",
            " 최종 평균 점수: 0.6806\n",
            "\n",
            "기본 RandomForest 검증 성능\n",
            " Accuracy: 0.6637\n",
            " F1 Score: 0.6647\n",
            " AUC: 0.7218\n",
            " 최종 평균 점수: 0.6834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Soft Voting"
      ],
      "metadata": {
        "id": "Mj-Pjv4-I7fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Soft Voting 앙상블 모델 생성\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lgbm', best_lgbm), ('rf', best_rf)],\n",
        "    voting='soft',  # 확률(Soft) Voting\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 앙상블 모델 학습\n",
        "voting_clf.fit(X_train_final, y_train_final)\n",
        "\n",
        "# 검증 데이터 예측\n",
        "y_val_proba_voting = voting_clf.predict_proba(X_val)[:, 1]\n",
        "y_val_pred_voting = (y_val_proba_voting >= 0.5).astype(int)  # 기본 임계값 0.5\n",
        "\n",
        "# 검증 데이터 성능 평가\n",
        "voting_acc = accuracy_score(y_val, y_val_pred_voting)\n",
        "voting_f1 = f1_score(y_val, y_val_pred_voting)\n",
        "voting_auc = roc_auc_score(y_val, y_val_proba_voting)\n",
        "voting_avg = (voting_acc + voting_f1 + voting_auc) / 3\n",
        "\n",
        "print(\"\\n Soft Voting 앙상블 검증 성능\")\n",
        "print(f\" Accuracy: {voting_acc:.4f}\")\n",
        "print(f\" F1 Score: {voting_f1:.4f}\")\n",
        "print(f\" AUC: {voting_auc:.4f}\")\n",
        "print(f\" 최종 평균 점수: {voting_avg:.4f}\")\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "test_proba_voting = voting_clf.predict_proba(X_test_scaled)[:, 1]\n",
        "test_pred_voting = (test_proba_voting >= 0.5).astype(int)\n",
        "\n",
        "# Test 데이터 예측 분포 확인\n",
        "unique_test, counts_test = np.unique(test_pred_voting, return_counts=True)\n",
        "pred_counts_test = dict(zip(unique_test, counts_test))\n",
        "\n",
        "print(\"\\n Test 데이터 예측 결과 (Soft Voting)\")\n",
        "print(f\"Class 0 개수: {pred_counts_test.get(0, 0)}\")\n",
        "print(f\"Class 1 개수: {pred_counts_test.get(1, 0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qnZeqEFI07J",
        "outputId": "f30bd9f6-535e-4ba3-a6ba-594c23adf789"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Soft Voting 앙상블 검증 성능\n",
            " Accuracy: 0.6696\n",
            " F1 Score: 0.6668\n",
            " AUC: 0.7281\n",
            " 최종 평균 점수: 0.6882\n",
            "\n",
            " Test 데이터 예측 결과 (Soft Voting)\n",
            "Class 0 개수: 4830\n",
            "Class 1 개수: 4685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threshold 튜닝 (최적 임계값 찾기)\n"
      ],
      "metadata": {
        "id": "7YwxL5dOM4SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Threshold 튜닝 함수 정의\n",
        "def find_best_threshold(y_true, y_probs):\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
        "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)  # 작은 수 더해서 0으로 나누기 방지\n",
        "    best_idx = np.argmax(f1_scores)\n",
        "    best_threshold = thresholds[best_idx]\n",
        "    best_f1 = f1_scores[best_idx]\n",
        "    print(f\"\\n Best Threshold 찾기 완료\")\n",
        "    print(f\" 최적 Threshold: {best_threshold:.4f}\")\n",
        "    print(f\" 최적 F1 Score: {best_f1:.4f}\")\n",
        "    return best_threshold\n",
        "\n",
        "# Voting 모델의 검증 데이터 확률 기반으로 최적 Threshold 찾기\n",
        "best_threshold = find_best_threshold(y_val, y_val_proba_voting)\n",
        "\n",
        "# 최적 Threshold를 적용해서 재예측\n",
        "y_val_pred_voting_best = (y_val_proba_voting >= best_threshold).astype(int)\n",
        "\n",
        "# 최적 Threshold 적용 후 성능 재평가\n",
        "voting_acc_best = accuracy_score(y_val, y_val_pred_voting_best)\n",
        "voting_f1_best = f1_score(y_val, y_val_pred_voting_best)\n",
        "voting_auc_best = roc_auc_score(y_val, y_val_proba_voting)\n",
        "voting_avg_best = (voting_acc_best + voting_f1_best + voting_auc_best) / 3\n",
        "\n",
        "print(\"\\n 최적 Threshold 적용 Soft Voting 검증 성능\")\n",
        "print(f\" Accuracy: {voting_acc_best:.4f}\")\n",
        "print(f\" F1 Score: {voting_f1_best:.4f}\")\n",
        "print(f\" AUC: {voting_auc_best:.4f}\")\n",
        "print(f\" 최종 평균 점수: {voting_avg_best:.4f}\")\n",
        "\n",
        "# 테스트 데이터 예측 - 최적 threshold 사용\n",
        "test_pred_voting_best = (test_proba_voting >= best_threshold).astype(int)\n",
        "\n",
        "# Test 데이터 예측 분포 확인\n",
        "unique_test_best, counts_test_best = np.unique(test_pred_voting_best, return_counts=True)\n",
        "pred_counts_test_best = dict(zip(unique_test_best, counts_test_best))\n",
        "\n",
        "print(\"\\n Test 데이터 예측 결과 (최적 Threshold 적용)\")\n",
        "print(f\"Class 0 개수: {pred_counts_test_best.get(0, 0)}\")\n",
        "print(f\"Class 1 개수: {pred_counts_test_best.get(1, 0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJV2JNubLtp1",
        "outputId": "f8a928e3-8726-4dc5-d5e5-0f73f36a239a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best Threshold 찾기 완료\n",
            " 최적 Threshold: 0.3192\n",
            " 최적 F1 Score: 0.6956\n",
            "\n",
            " 최적 Threshold 적용 Soft Voting 검증 성능\n",
            " Accuracy: 0.5993\n",
            " F1 Score: 0.6956\n",
            " AUC: 0.7281\n",
            " 최종 평균 점수: 0.6744\n",
            "\n",
            " Test 데이터 예측 결과 (최적 Threshold 적용)\n",
            "Class 0 개수: 1781\n",
            "Class 1 개수: 7734\n"
          ]
        }
      ]
    }
  ]
}