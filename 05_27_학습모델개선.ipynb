{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erika0915/pattern-recognition/blob/main/05_27_%ED%95%99%EC%8A%B5%EB%AA%A8%EB%8D%B8%EA%B0%9C%EC%84%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm3VWYe4JZpU",
        "outputId": "01d7eb98-4966-48bc-984b-a1a07cdf2e22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOxF8qgcL66S",
        "outputId": "44ed2457-84bf-48cc-a5b7-1742f461dc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 주요 라이브러리 import\n"
      ],
      "metadata": {
        "id": "9fQIt06PRfTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "Lj0WTFebK8tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리\n"
      ],
      "metadata": {
        "id": "KKdsbNdoQbG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-RWj9D4IvMd"
      },
      "outputs": [],
      "source": [
        "# 학습 및 테스트 데이터 불러오기\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/패턴인식/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/패턴인식/test.csv')\n",
        "\n",
        "# 불필요한 컬럼 제거\n",
        "train_df = train_df.drop(columns=['id', 'shares'])\n",
        "\n",
        "# 수치형 변수 이상치 처리 : 로그 변환으로 값의 분포 완화\n",
        "def log1p(x):\n",
        "    return np.log1p(np.maximum(x, 0))\n",
        "\n",
        "log_transform_cols = [\n",
        "    'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos',\n",
        "    'self_reference_avg_shares', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
        "    'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'kw_avg_avg'\n",
        "]\n",
        "\n",
        "for col in log_transform_cols:\n",
        "    if col in train_df.columns:\n",
        "        train_df[col] = log1p(train_df[col])\n",
        "    if col in test_df.columns:\n",
        "        test_df[col] = log1p(test_df[col])\n",
        "\n",
        "# 결측치 처리 : 수치형은 중앙값, 범주형은 최빈값으로 대체\n",
        "numeric_cols = train_df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_cols = train_df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "y = train_df['y']\n",
        "X = train_df.drop(columns=['y'])\n",
        "\n",
        "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "train_median = X[numeric_cols].median()\n",
        "train_mode = X[categorical_cols].mode().iloc[0]\n",
        "\n",
        "X[numeric_cols] = X[numeric_cols].fillna(train_median)\n",
        "X[categorical_cols] = X[categorical_cols].fillna(train_mode)\n",
        "\n",
        "test_df[numeric_cols] = test_df[numeric_cols].fillna(train_median)\n",
        "test_df[categorical_cols] = test_df[categorical_cols].fillna(train_mode)\n",
        "\n",
        "# 수치형 변수 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(test_df[numeric_cols]), columns=numeric_cols)\n",
        "\n",
        "# 범주형 변수 One-hot 인코딩\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "X_train_cat = pd.DataFrame(encoder.fit_transform(X[categorical_cols]), columns=encoder.get_feature_names_out())\n",
        "X_test_cat = pd.DataFrame(encoder.transform(test_df[categorical_cols]), columns=encoder.get_feature_names_out())\n",
        "\n",
        "# 테스트 데이터셋에 없는 칼럼 채워넣기 (0으로)\n",
        "missing_cols = set(X_train_cat.columns) - set(X_test_cat.columns)\n",
        "for col in missing_cols:\n",
        "    X_test_cat[col] = 0\n",
        "X_test_cat = X_test_cat[X_train_cat.columns]\n",
        "\n",
        "# 최종 결합\n",
        "X_train_final = pd.concat([X_train_scaled.reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
        "X_test_final = pd.concat([X_test_scaled.reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# 검증용 데이터 분리 (train/validation = 8:2, stratify로 클래스 비율 유지)\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "     X_train_final, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 테스트용 ID 백업 (예측 결과 저장용)\n",
        "test_id = test_df['id'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습"
      ],
      "metadata": {
        "id": "dgA_l-m7RMB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파생 변수 생성 함수 정의\n",
        "def add_engineered_features(df):\n",
        "    df = df.copy()\n",
        "    df['keyword_ratio'] = (df['num_keywords'] + 1) / (df['n_tokens_content'] + 1)\n",
        "    df['token_density'] = (df['n_tokens_content'] + 1) / (df['num_imgs'] + 1)\n",
        "    df['href_self_ratio'] = (df['num_self_hrefs'] + 1) / (df['num_hrefs'] + 1)\n",
        "    df['stopword_diversity'] = (df['n_non_stop_unique_tokens'] + 1e-5) / (df['n_non_stop_words'] + 1e-5)\n",
        "    df['keyword_score_max'] = df['kw_max_max'] / (df['num_keywords'] + 1)\n",
        "    df['keyword_score_avg'] = df['kw_avg_avg'] / (df['num_keywords'] + 1)\n",
        "    df['keyword_contrast'] = df['kw_max_max'] - df['kw_min_min']\n",
        "\n",
        "    return df\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터에 파생 변수 적용\n",
        "X_train = add_engineered_features(X_train_split)\n",
        "X_val = add_engineered_features(X_val_split)\n",
        "X_test = add_engineered_features(X_test_final)"
      ],
      "metadata": {
        "id": "iVzisWPHKLpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 불균형 해결을 위한 SMOTE 오버샘플링\n",
        "sm = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train_split)\n",
        "\n",
        "# Base learners\n",
        "lgbm = LGBMClassifier(n_estimators=300, max_depth=7, learning_rate=0.05, random_state=42)\n",
        "xgb = XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.05, eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
        "cat = CatBoostClassifier(n_estimators=300, max_depth=6, learning_rate=0.05, verbose=0, random_state=42)\n",
        "\n",
        "# Meta model (XGBoost 사용)\n",
        "meta_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# StackingClassifier 정의\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=[('lgbm', lgbm), ('xgb', xgb), ('cat', cat)],\n",
        "    final_estimator=meta_model,\n",
        "    passthrough=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 학습\n",
        "stacking_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# 검증 및 테스트셋의 컬럼 순서를 학습 데이터와 동일하게 정렬\n",
        "X_val = X_val[X_resampled.columns]\n",
        "X_test = X_test[X_resampled.columns]\n",
        "\n",
        "# 훈련셋에서 최적의 임계값(Threshold)을 찾기 위한 F1 Score 기반 탐색\n",
        "train_probs = stacking_model.predict_proba(X_resampled)[:, 1]\n",
        "thresholds = np.linspace(0.1, 0.9, 81)\n",
        "f1_scores = [(t, f1_score(y_resampled, (train_probs >= t).astype(int))) for t in thresholds]\n",
        "best_threshold, best_f1 = max(f1_scores, key=lambda x: x[1])\n",
        "\n",
        "# 최적 임계값 기준으로 검증 세트 예측 수행\n",
        "val_probs = stacking_model.predict_proba(X_val)[:, 1]\n",
        "val_preds = (val_probs >= best_threshold).astype(int)\n",
        "\n",
        "# 검증 세트 평가 지표 계산\n",
        "acc = accuracy_score(y_val_split, val_preds)\n",
        "f1 = f1_score(y_val_split, val_preds)\n",
        "auc = roc_auc_score(y_val_split, val_probs)\n",
        "avg = (acc + f1 + auc) / 3\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"\\n[Validation 최적 임계값]: {best_threshold:.2f} (F1: {best_f1:.4f})\")\n",
        "print(\"[Validation 성능]\")\n",
        "print(f\" - Accuracy: {acc:.4f}\")\n",
        "print(f\" - F1 Score:  {f1:.4f}\")\n",
        "print(f\" - AUC:       {auc:.4f}\")\n",
        "print(f\" - 평균 점수:  {avg:.4f}\")"
      ],
      "metadata": {
        "id": "arq1qplYLttP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 데이터 분포 확인"
      ],
      "metadata": {
        "id": "bx9SA_cOQW-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 확률 예측\n",
        "test_probs = stacking_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 최적 임계값 적용해 0 또는 1로 변환\n",
        "test_preds = (test_probs >= best_threshold).astype(int)\n",
        "unique, counts = np.unique(test_preds, return_counts=True)\n",
        "\n",
        "print(\"\\n▶ 테스트 세트 예측 클래스 분포:\")\n",
        "print(pd.Series(test_preds).value_counts().to_string())\n"
      ],
      "metadata": {
        "id": "RCOfcFPVQVHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction.csv 저장\n",
        "prediction = pd.DataFrame({'id': test_id, 'y_predict': test_preds, 'y_prob': test_probs})\n",
        "prediction.to_csv('/content/prediction.csv', index=False)"
      ],
      "metadata": {
        "id": "QqZMG-5FVEn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}